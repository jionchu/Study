## 1. 음성인식 기술
- 인간의 말을 문자로 자동 변환하는 기술

### 음성인식의 어려움
- 동일한 화자인 경우에도 다양한 변이: 음의 높낮이, 발성 속도, 주변 잡음의 영향
- 동일한 단어라도 화자별로 발성이 다름: 음색, 발음, 강세 등
- 문맥에 따라 발성이 달라짐: 음운 변화 (자음접변, 구개음화, 경음화)
⇒ 음성인식에 deep neural net을 적용하면서 성능 대폭 개선

### 이미지 인식과 음성인식의 차이
음성인식은 frame이 아니라 sequence에 담긴 정보를 처리해야 함

## 2. Hidden Markov Model (HMM)
### Markov chain
미래 상태(state)의 조건부 확률 분포가 현재 상태에 의해서만 결정됨 (과거의 상태와 독립적)
- Time-homogeneous Markov chain (시간에 따라 확률이 변하지 않음)
- 3 states & left-to-right transition

### Hidden
latent, probabilistic

음성신호의 dynamics는 HMM으로 모델링하고 각 state에서의 관측확률은 GMM, DNN, LSTM 등으로 모델링함  

### 음성 인식
입력 음성 신호에 대해 가장 확률이 높은 hidden state sequence를 구하는 것 (거의 대부분의 경우 단어열 파악)  

## 3. GMM-HMM
### 단계
- 특징(feature) 추출(extraction)
- Gaussian Mixture Modeling

### 특징 추출 과정
- Waveform (Frame 단위)
- Spectrum
- Mel-scaled filterbank energy
- Mel-scaled cepstral coefficient (MSCC)
- Dynamics를 고려: Static MFCC + Delta + Acc + alpha

### Gaussian Mixture Model (GMM)
- 각 state에서 특징 벡터의 관측확률 분포를 Gaussian들의 weighted summation으로 모델링

## 4. DNN-HMM
if DB , DNN >> GMM (ERR 20-30%)

## 5. LSTM-HMM
DNN → RNN LSTM (ERR > 10%)

## 6. End-to-end AM
### End-to-end AM
- 기존 hybrid 모델(DNN-HMM, LSTM-HMM 등)에서 HMM을 제거
- RNN(LSTM)-CTC

### 신경망 학습 과정의 loss function (Objective ft.)
- LSTM-HMM
  - Cross-entropy(XE)
  - 매 frame마다 정답(HMM state index)과 출력값(state의 post, prob)으로부터 XE loss를 구하고, 이를 back propagation하여 parameter estimation
  - 주어진 입력 발화를 forced aligning → 매 frame마다의 정답 label로 사용

- LSTM-CTC
  - 발화 단위에서 CTC loss를 구하여 parameter estimation
  - CTC loss
    - Soft target alignment에서 XE loss
    - 가능한 모든 alignment

- CTC: Connectionist Temporal Classifier
  - Naming
    - Temporal Classification: Task of labeling unsegmented data sequences
    - CTC: Use of RNNs for this purpose
  - CTC는, 주어진 입력 발화에 대해, 모델(RNN LSTM) parameter를 최적화하여 label sequence의 log likelihood를 최대화하고자 함

참고: https://www.youtube.com/watch?v=XhjPqGKF9Zs
