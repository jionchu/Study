## 1. 언어지능
인간의 가장 중요한 **정보전달, 축적 및 의사소통 수단**인 '언어'를 다루는 기술
- HCI(Human Computer Interaction)의 핵심기술
- 지식 및 정보 서비스의 기반 기술
- 민족 고유의 문화 산업을 발전시키기 위한 기반 기술

### 주요 기술
- 음성인식, 음성합성, 대화처리, 자연어처리, 질의응답 등

### 언어의 특성
- 분절성: 연속적인 세계를 끊어서 표현
- 개방성: 무한한 표현이 가능 (=창조성)
- 추상성: 개념화, 일반화
  ex) 장미, 백합, 튤립 -> 잎, 줄기, 향기가 있음 -> 꽃
- 체계적: 규칙과 구조를 가짐 (ex: 문법구조)

### 언어를 담당하는 뇌의 영역
- Broca (언어의 구조)
- Wernicke (언어의 의미)

## 2. 음성인식 기술
- 인간의 말을 문자로 자동 변환하는 기술

### 음성인식의 어려움
- 동일한 화자인 경우에도 다양한 변이: 음의 높낮이, 발성 속도, 주변 잡음의 영향
- 동일한 단어라도 화자별로 발성이 다름: 음색, 발음, 강세 등
- 문맥에 따라 발성이 달라짐: 음운 변화 (자음접변, 구개음화, 경음화)
⇒ 음성인식에 deep neural net을 적용하면서 성능 대폭 개선

### 이미지 인식과 음성인식의 차이
음성인식은 frame이 아니라 sequence에 담긴 정보를 처리해야 함

## 3. Hidden Markov Model (HMM)
### Markov chain
미래 상태(state)의 조건부 확률 분포가 현재 상태에 의해서만 결정됨 (과거의 상태와 독립적)
- Time-homogeneous Markov chain (시간에 따라 확률이 변하지 않음)
- 3 states & left-to-right transition

### Hidden
latent, probabilistic

음성신호의 dynamics는 HMM으로 모델링하고 각 state에서의 관측확률은 GMM, DNN, LSTM 등으로 모델링함  

### 음성 인식
입력 음성 신호에 대해 가장 확률이 높은 hidden state sequence를 구하는 것 (거의 대부분의 경우 단어열 파악)  

## 4. GMM-HMM
### 단계
- 특징(feature) 추출(extraction)
- Gaussian Mixture Modeling

### 특징 추출 과정
- Waveform (Frame 단위)
- Spectrum
- Mel-scaled filterbank energy
- Mel-scaled cepstral coefficient (MSCC)
- Dynamics를 고려: Static MFCC + Delta + Acc + alpha

### Gaussian Mixture Model (GMM)
- 각 state에서 특징 벡터의 관측확률 분포를 Gaussian들의 weighted summation으로 모델링

## 5. DNN-HMM
if DB , DNN >> GMM (ERR 20-30%)

## 6. LSTM-HMM
DNN → RNN LSTM (ERR > 10%)

## 7. End-to-end AM
### End-to-end AM
- 기존 hybrid 모델(DNN-HMM, LSTM-HMM 등)에서 HMM을 제거
- RNN(LSTM)-CTC

### 신경망 학습 과정의 loss function (Objective ft.)
- LSTM-HMM
  - Cross-entropy(XE)
  - 매 frame마다 정답(HMM state index)과 출력값(state의 post, prob)으로부터 XE loss를 구하고, 이를 back propagation하여 parameter estimation
  - 주어진 입력 발화를 forced aligning → 매 frame마다의 정답 label로 사용

- LSTM-CTC
  - 발화 단위에서 CTC loss를 구하여 parameter estimation
  - CTC loss
    - Soft target alignment에서 XE loss
    - 가능한 모든 alignment

- CTC: Connectionist Temporal Classifier
  - Naming
    - Temporal Classification: Task of labeling unsegmented data sequences
    - CTC: Use of RNNs for this purpose
  - CTC는, 주어진 입력 발화에 대해, 모델(RNN LSTM) parameter를 최적화하여 label sequence의 log likelihood를 최대화하고자 함

참고: https://www.youtube.com/watch?v=XhjPqGKF9Zs
