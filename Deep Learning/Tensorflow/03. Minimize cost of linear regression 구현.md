# 03. Minimize cost of linear regression 구현

## 1. Draw a cost function

### matplotlib
```python
import tensorflow as tf
import matplotlib.pyplot as plt

X = [1,2,3]
Y = [1,2,3]

W = tf.placeholder(tf.float32)
# Our hypothesis for linear model X * W
hypothesis = X * W

# cost/loss function
cost = tf.reduce_mean(tf.square(hypothesis - Y))
# Launch the graph in a session
sess = tf.Session()
# Initializes global variables in the graph
sess.run(tf.global_variables_initializer())
```
### Variables for plotting cost function
```python
W_val = []
cost_val = []
```

### cost 계산
- feed_W를 feed_dict로 session의 W에 넣고 계산
```python
for i in range(-30,50):
    feed_W = I * 0.1
    curr_cost, curr_W = sess.run([cost, W], feed_dict={W:feed_W})
    W_val.append(curr_W)
    cost_val.append(curr_cost)
```
### Draw the graph
```python
plt.plot(W_val, cost_val)
plt.show()
```
![cost function](https://github.com/jionchu/Study/blob/master/Deep%20Learning/DeepLearningZeroToAll/images/tensorflow-const-function-graph.png)  

## 2. Minimize cost
### Cost/loss function
```python
import tensorflow as tf

x_data = [1,2,3]
y_data = [1,2,3]

W = tf.Variable(tf.random_normal([1]), name='weight')
X = tf.placeholder(tf.float32)
Y = tf.placeholder(tf.float32)

# Our hypothesis for linear model X * W
hypothesis = X * W

# cost/loss function
cost = tf.reduce_sum(tf.square(hypothesis – Y))
```

### Minimize
- <img src="https://latex.codecogs.com/svg.latex?\;W:=W-\alpha\frac{1}{m}\sum_{i=1}^{m}(Wx^{(i)}-y^{(i)})x^{(i)}" title="partial deirivative" />
- Gradient Descent using derivative
- W -= learning_rate * derivative
- 기울기를 구해서 learning_rate를 곱하여 W에서 빼기
- 기울기가 양수인 경우, W는 작아짐
- 기울기가 음수인 경우, W는 커짐
- 기울기가 0인 곳을 찾아감

```python
learning_rate = 0.1
gradient = tf.reduce_mean((W * X - Y) * X)
descent = W - learning_rate * gradient
update = W.assign(descent) # tensorflow에서는 =로 assign할 수 없음
```

### Run the graph in a session
- cost는 점점 작아지고 W는 1(위의 그래프를 보고 예상한 값)에 가까워짐
```python
sess = tf.Session()
# Initializes global variables in the graph
sess.run(tf.global_variables_initializer())
for step in range(21):
    # update를 실행시킴
    sess.run(update, feed_dict={X:x_data, Y:y_data})
    print(step, sess.run(cost, feed_dict={X:x_data,Y:y_data}), sess.run(W))
```

## 3. Optimizer
- tensorflow를 이용하면 cost를 직접 미분하지 않아도 tensorflow가 자동으로 이 일을 해줌
```python
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)
train = optimizer.minimize(cost)
```

## 4. Get gradients

### Set wrong model weight
```python
W = tf.Variable(5.0)
```

### Get gradients
```python
gvs = optimizer.compute_gradients(cost)
```

### Apply gradients
- 원하는 대로 gradient를 수정해서 사용할 수 있음
```python
apply_gradients = optimizer.apply_gradients(gvs)
```

### Run the graph in a session
```python
# Launch the graph in a session
sess = tf.Session()
# Initializes global variables in the graph
sess.run(tf.global_variables_initializer())

for step in range(100):
    sess.run(apply_gradient)
    print(step, sess.run([gradient, W, gvs]))

```