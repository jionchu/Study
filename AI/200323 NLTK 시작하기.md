# NLTK 시작하기

- NLTK 설치 및 nltk data 다운로드
- nltk data 이용하기
- Matplotlib
- Counting Vocabulary
- FreqDist, bigram

## 1. NLTK 설치 및 nltk data 다운로드
```
pip install nltk
```

### nltk 설치 후 nltk data 다운로드
```python
import nltk
nltk.download()
```

### NLTK 설치 파일 위치 찾기
```python
nltk.__file__
```
```
'C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\nltk\\__init__.py'
```

## 2. nltk data 이용하기
### nltk data에서 book text 전체 출력
```python
from nltk.book import *
```
```
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
```

### 각각의 text 객체 출력하기
```python
text1
```
```
<Text: Moby Dick by Herman Melville 1851>
```
```python
text2
```
```
<Text: Sense and Sensibility by Jane Austen 1811>
```

### 모든 text의 크기 알아보기
```python
texts = [text1,text2,text3,text4,text5,text6,text7,text8,text9]
for text in texts:
	print(text,len(text))
```
```
<Text: Moby Dick by Herman Melville 1851> 260819
<Text: Sense and Sensibility by Jane Austen 1811> 141576
<Text: The Book of Genesis> 44764
<Text: Inaugural Address Corpus> 149797
<Text: Chat Corpus> 45010
<Text: Monty Python and the Holy Grail> 16967
<Text: Wall Street Journal> 100676
<Text: Personals Corpus> 4867
<Text: The Man Who Was Thursday by G . K . Chesterton 1908> 69213
```

### 모든 sentence 출력하기
```python
sents = [sent1,sent2,sent3,sent4,sent5,sent6,sent7,sent8,sent9]
for sent in sents:
	print(len(sent),sent)
```
```
4 ['Call', 'me', 'Ishmael', '.']
11 ['The', 'family', 'of', 'Dashwood', 'had', 'long', 'been', 'settled', 'in', 'Sussex', '.']
11 ['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.']
13 ['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', 'and', 'of', 'the', 'House', 'of', 'Representatives', ':']
11 ['I', 'have', 'a', 'problem', 'with', 'people', 'PMing', 'me', 'to', 'lol', 'JOIN']
17 ['SCENE', '1', ':', '[', 'wind', ']', '[', 'clop', 'clop', 'clop', ']', 'KING', 'ARTHUR', ':', 'Whoa', 'there', '!']
18 ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']
14 ['25', 'SEXY', 'MALE', ',', 'seeks', 'attrac', 'older', 'single', 'lady', ',', 'for', 'discreet', 'encounters', '.']
23 ['THE', 'suburb', 'of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as', 'red', 'and', 'ragged', 'as', 'a', 'cloud', 'of', 'sunset', '.']
```

### Concorance
입력한 단어가 쓰인 문장들을 보여줌
```python
text1.concordance("monstrous")
```
```
Displaying 11 of 11 matches:
ong the former , one was of a most monstrous size . ... This came towards us , 
ON OF THE PSALMS . " Touching that monstrous bulk of the whale or ork we have r
ll over with a heathenish array of monstrous clubs and spears . Some were thick
d as you gazed , and wondered what monstrous cannibal and savage could ever hav
that has survived the flood ; most monstrous and most mountainous ! That Himmal
they might scout at Moby Dick as a monstrous fable , or still worse and more de
th of Radney .'" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l
ing Scenes . In connexion with the monstrous pictures of whales , I am strongly
ere to enter upon those still more monstrous stories of them which are to be fo
ght have been rummaged out of this monstrous cabinet there is no telling . But 
of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u
```

## 3. Matplotlib
matplotlib 설치
```
pip install matplotlib
```
### 단어의 빈도 확인하기
text4(취임연설문)에서 다음 단어들이 얼마나 사용되었는지 그래프로 나타낼 수 있다.  
```python
text4.dispersion_plot(["citizens","democracy","freedom","duties","America"])
```
![dispersion_plot](https://github.com/jionchu/Study/blob/master/AI/images/dispersion_plot_ex.PNG)  

### 사용자가 입력한 임의의 3개의 키워드에 대한 9개 text의 plot 모두 그리기
```python
wordList = []
for i in range(3):
    word = input("Enter a word: ")
    wordList.append(word)
```
```
Enter a word: america
Enter a word: love
Enter a word: murder
```
```python
texts = [text1,text2,text3,text4,text5,text6,text7,text8,text9]
for text in texts:
    print(text)
	text.dispersion_plot(wordList)
```
각 text에 대한 plot이 차례대로 뜬다.  

## 4. Counting Vocabulary
### set()
중복 제거
```python
len(text3)
```
```
44764
```
중복 제거
```python
len(set(text3))
```
```
2789
```
```python
len(set(text3))/len(text3)
```
```
0.06230453042623537
```

### 어휘 다양성 계산하기
먼저 lexical_diversity 함수를 정의한다.
```python
def lexical_diversity(text):
    return(len(set(text))/len(text))

def percentage(count, total):
    return(100*count/total)
```
```python
lexical_diversity(text3)
```
```
0.6230453042623537
```
```python
lexical_diversity(text5)
```
```
0.13477005109975562
```
입력한 단어가 몇 퍼센트 있는지 계산
```python
percentage(text4.count('a'),len(text4))
```
```
1.4643016433938312
```

## 5. FreqDist, bigram
단순 파이썬 코딩으로 하기 힘든 작업을 NLTK의 FreqDist(), bigram()과 같은 메소드를 사용하여 쉽게 수행할 수 있다.  

### 모든 text에 대한 가장 많이 나오는 단어 출력하기
```python
for text in texts:
    fd = nltk.FreqDist(text)
    print(text, fd.most_common(5))
```
```
<Text: Moby Dick by Herman Melville 1851> [(',', 18713), ('the', 13721), ('.', 6862), ('of', 6536), ('and', 6024)]
<Text: Sense and Sensibility by Jane Austen 1811> [(',', 9397), ('to', 4063), ('.', 3975), ('the', 3861), ('of', 3565)]
<Text: The Book of Genesis> [(',', 3681), ('and', 2428), ('the', 2411), ('of', 1358), ('.', 1315)]
<Text: Inaugural Address Corpus> [('the', 9446), ('of', 7087), (',', 7045), ('and', 5146), ('.', 4856)]
<Text: Chat Corpus> [('.', 1268), ('JOIN', 1021), ('PART', 1016), ('?', 737), ('lol', 704)]
<Text: Monty Python and the Holy Grail> [(':', 1197), ('.', 816), ('!', 801), (',', 731), ("'", 421)]
<Text: Wall Street Journal> [(',', 4885), ('the', 4045), ('.', 3828), ('of', 2319), ('to', 2164)]
<Text: Personals Corpus> [(',', 539), ('.', 353), ('/', 110), ('for', 99), ('and', 74)]
<Text: The Man Who Was Thursday by G . K . Chesterton 1908> [(',', 3488), ('the', 3291), ('.', 2717), ('a', 1713), ('of', 1710)]
```

### Frequency Distribution
```python
fdist1 = FreqDist(text1)
print(fdist1)
```
```
<FreqDist with 19317 samples and 260819 outcomes>
```
```python
fdist1.most_common(50)
```
```
[(',', 18713), ('the', 13721), ('.', 6862), ('of', 6536), ('and', 6024), ('a', 4569), ('to', 4542), (';', 4072), ('in', 3916), ('that', 2982), ("'", 2684), ('-', 2552), ('his', 2459), ('it', 2209), ('I', 2124), ('s', 1739), ('is', 1695), ('he', 1661), ('with', 1659), ('was', 1632), ('as', 1620), ('"', 1478), ('all', 1462), ('for', 1414), ('this', 1280), ('!', 1269), ('at', 1231), ('by', 1137), ('but', 1113), ('not', 1103), ('--', 1070), ('him', 1058), ('from', 1052), ('be', 1030), ('on', 1005), ('so', 918), ('whale', 906), ('one', 889), ('you', 841), ('had', 767), ('have', 760), ('there', 715), ('But', 705), ('or', 697), ('were', 680), ('now', 646), ('which', 640), ('?', 637), ('me', 627), ('like', 624)]
```
```python
fdist1['whale']
```
```
906
```

### List Comprehension
```python
V = set(text1)
long_words = [w for w in V if len(w)>15]
sorted(long_words)
```
```
['CIRCUMNAVIGATION', 'Physiognomically', 'apprehensiveness', 'cannibalistically', 'characteristically', 'circumnavigating', 'circumnavigation', 'circumnavigations', 'comprehensiveness', 'hermaphroditical', 'indiscriminately', 'indispensableness', 'irresistibleness', 'physiognomically', 'preternaturalness', 'responsibilities', 'simultaneousness', 'subterraneousness', 'supernaturalness', 'superstitiousness', 'uncomfortableness', 'uncompromisedness', 'undiscriminating', 'uninterpenetratingly']
```

### Bigrams
n-gram이란 주어진 단어들 중 n개의 연속된 단어를 묶은 것을 말한다.
- size가 1인 경우 **unigram**
- size가 2인 경우 **bigram**
- size가 3인 경우 **trigram**

```python
list(nltk.bigrams(['time','flies','like','an','arrow']))
```
```
[('time', 'flies'), ('flies', 'like'), ('like', 'an'), ('an', 'arrow')]
```

### Bigram 함수 구현
```python
def myBigram(myList):
    result = []
    for i in range(len(myList)-1):
        result.append((myList[i],myList[i+1]))
    return result
```

### Collocations
연속적으로 많이 쓰이는 단어들
```python
text1.collocations()
```
```
Sperm Whale; Moby Dick; White Whale; old man; Captain Ahab; sperm Whale; Right Whale; Captain Peleg; New Bedford; Cape Horn; cried Ahab; years ago; lower jaw; never mind; Father Mapple; cried Stubb; chief mate; white whale; ivory leg; one hand
```
위와 같은 결과가 나와야 하는데 다음과 같은 오류가 발생함
```
ValueError: too many values to unpack (expected 2)
```

### 마코프 모델
다음에 나올 말을 예측

