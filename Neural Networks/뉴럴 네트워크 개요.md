# 뉴럴 네트워크 개요

## 1. 목표
- 근본적으로 모든 형태의 데이터를 다룰 수 있는 단일 메커니즘 만들기
- 어떠한 형태로도 가공되지 않은 데이터를 지식으로 바꿔서 실행할 수 있는 비즈니스 통찰력을 얻거나, 짐을 줄이는 서비스를 만들거나, 생명을 살리는 약을 만들어 내는 것

## 2. 다루는 도구
1. **케라스 (Keras)**
2. **텐서플로 (TensorFlow)**

케라스와 텐서플로는 딥러닝 프레임워크로 다음과 같은 특징이 있다.
- 매우 널리 알려져 있음
- 대규모 커뮤니티의 지원을 받고 있음
- 다른 유명한 백엔드 및 프론트엔드 프레임워크(Theano, Caffe, Node.js)와의 호환성이 매우 높음

### 1) 케라스
![keras](https://github.com/jionchu/TIL/blob/master/Neural%20Networks/images/keras.png)  
뉴럴 네트워크에서의 고차원적인 애플리케이션 프로그래밍 인터페이스
- 파이썬으로 구현되어 있음
- 딥러닝의 공용어라고 불림
- 사용자 친화적
- 모듈화 되어 있음
- 높은 확장성 제공
- 빠른 실험의 실행에 초점

#### 케라스의 주요 기능
- 쉽고 빠른 프로토타이핑
- 사전 구현된 다양한 최신 뉴럴 네트워크 아키텍쳐 (이미 학습이 완료된 모델과 실험 데이터셋 포함)
- 다양한 CPU와 GPU에서 실행

### 2) 텐서플로
![tensorflow](https://github.com/jionchu/TIL/blob/master/Neural%20Networks/images/tensorflow.png)  
고성능 수치 계산용 오픈소스 소프트웨어 라이브러리
- 텐서(tensor)라고 불리는 데이터 표현을 사용
- 데이터플로우 그래프를 구현할 수 있음

텐서플로에서 제공하는 API를 활용하면 다양한 플랫폼(CPU, GPU 및 TPU(Tensor Processing Units)), 데스크톱에서부터 서버 클러스터, 모바일, 엣지 장비까지 쉽게 연산을 수행할 수 있다.

#### 데이터플로우 그래프
네트워크나 프로세싱 뉴런에서 일어나는 일련의 데이터 흐름을 기술하는 구조  
네트워크상의 모든 뉴런은 수학적 오퍼레이션이며, 뉴런 사이의 각 연결(혹은 edge)은 다차원의 데이터 배열이나 텐서이다.

## 3. 뉴럴 학습 기본
### 1) 뉴럴 네트워크
- 뉴럴 네트워크는 데이터가 네트워크상으로 전달될 때 국지적인 소규모 연산을 수행하는 **다양한 알고리즘의 조합**으로 이루어진다.  
- 뉴럴 네트워크란 네트워크에 입력한 값(ex. 이미지 등)과 관심을 갖고 있는 대상(ex. 이미지에 고양이가 있는지 등)의 관계를 **스스로 학습**하는 하나의 메커니즘이다.  

어떻게 다양한 형태와 크기의 데이터를 받아들이고 각 입력에 해당하는 결과를 생성할 수 있을까?  
⇒ 자연이 문제를 해결하는 방식을 활용

### 2) 두뇌 관찰
뉴럴 네트워크가 사람의 두뇌와 동일하게 동작하는 것은 아니지만 둘을 비교함으로써 데이터에 담긴 연관된 패턴을 추출할 수 있는 시스템을 설계하는 데 필요한 워크플로우를 더 잘 이해할 수 있다.

#### a. 생리적 두뇌 구현
신경세포인 **뉴런(Neuron)**
- 뉴런을 특정한 형태로 완벽하게 연결할 수 있다면 불, 농업, 우주여행을 발견한 **두뇌**를 얻을 수 있다.
- 따라서 사람들은 뉴런이 학습하는 방법을 알아내려고 하며 그러기 위해 우선 하나의 뉴런이 어떻게 동작하는지 알아야 한다.

#### b. 뉴런의 생리학
하나의 뉴런은 전기와 화학적인 신호로 정보를 받아들이고 처리한 후 전달하는 전기적 흥분 세포일 뿐이다.  
세포 조직은 다른 뉴런으로부터 메시지를 받아들인다. 뉴런이 메시지를 받거나 보낸다고 표현하는 것은 실제로는 뉴런이 **축색돌기를 통해 전기적인 임펄스를 전송**하는 것이다.
1. 뉴런에 적절한 임펄스를 가하면 **action potential**이라고 알려진 전기적 이벤트를 만들어낸다.
2. 뉴런이 action potential(혹은 spike)에 다다르면 뉴런은 **신경 전달 물질**을 방출한다. 신경 전달 물질은 화학 물질의 하나로, 다른 뉴런에 도달할 때까지 **시냅스** 사이의 매우 짧은 거리를 이동한다. 뉴런이 action potential에 이를 때마다 신경 전달 물질은 수백 개의 시냅스에서 방출되어 다른 뉴런의 **축색돌기**에 이른다.
3. 축색돌기와 연결된 뉴런은 임펄스의 특성에 따라 다시 action potential을 유발한다.

이러한 과정이 반복되어 뉴런 네트워크가 소통하고, 계산하고, 협업하면서 복잡한 문제를 해결한다.

결국 뉴런은 전기적 입력을 받아 몇 가지 처리를 거쳐 결과가 **양**(positive)이면 방출하고 **음**(negative)이면 아무런 동작도 하지 않는다.  
⇒ 처리 값이 양이라는 것은 어떤 의미인가? 이것을 이해하기 위해 뇌에서 정보나 지식을 표현하는 방법을 살펴보자.

#### c. 정보 표현
예를 들어 개, 고양이, 헬리콥터 이미지를 구분해야 한다고 생각해보자.  

1. 우리는 3개의 **전문가 뉴런**을 고용해 이미지를 구분하는 태스크를 수행한다. 각 전문가 뉴런은 개, 고양이, 헬리콥터의 지식을 가진 전문가다. 각자 다양한 종류의 개나 고양이 또는 헬리콥터의 정보를 수집하고 표현할 수 있다.  
2. 우리가 3개의 전문가 뉴런들에게 개 이미지를 보여주면 개 전문가 뉴런이 즉시 알아보고 **신경 전달 물질을 방출**한다. 마찬가지로 고양이 이미지를 보여주면 고양이 전문가 뉴런이 자신이 고양이를 발견했다는 신경 전달 물질을 방출한다.  

이것이 뉴런이 실세계의 물체를 표현하는 방식과 동일하지는 않지만 뉴런에 기반을 둔 학습 시스템을 기능적으로 이해하는 데는 도움이 될 것이다.

#### d. 뉴럴 인코딩의 미스터리
앞에서 본 것처럼 하나의 전문가 뉴런만으로 하나의 대상을 구분할 수 있는 것은 아니다.  

많은 신경과학자들의 분산 이론에 따르면
- 뉴런을 활성화하는 고유한 형태를 가진 특정한 자극(ex. 고양이 이미지)은 뇌 전체에 널리 퍼진다. 예를 들어 고양이 이미지는 100개의 서로 다른 뉴런에 전달된다.
- 각 뉴런은 이미지에서 고양이가 가진 형태(ex. 귀, 꼬리, 눈, 몸의 모양 등)를 식별하는데 특화되어 있다.

즉 몇 개의 고양이 전문가 뉴런은 다른 뉴런과 조합되어 고양이의 요소를 가진 다른 이미지 또한 표현할 수 있다.

#### e. 분산된 표현과 학습
이러한 분산된 표상 덕분에 사람의 두뇌는 매우 적은 데이터만으로도 추론을 할 수 있다.

예를 들어 이미지가 버스인지 토스터인지 신뢰할 수 있을 정도로 구분하려면 뉴럴 네트워크는 수백 장의 이미지를 사용해서 학습시켜야 하지만 사람은 다섯 장의 이미지만 봐도 뉴럴 네트워크만큼의 정확도를 보여준다.

## 4. 데이터 과학 기본
데이터 과학의 기본 용어와 개념들

### 1) 정보 이론
- 실세계에서의 정보 신호 처리와 관련된 개념
- 신호 하나가 제공하는 정보의 양을 정량화하는 과학

정보 이론 분야에서는 직관적 지식을 코드화한다. 예를 들어 다음과 같은 관념들이 있다.
- 발생 가능성이 낮은 이벤트는 적은 정보를 가진다.
- 발생 가능성이 높은 이벤트는 많은 정보를 가진다.
- 발생이 보장된 이벤트는 아무런 정보도 갖지 않는다.
- 독립적인 발생 가능성을 가진 이벤트는 추가적인 정보를 가진다.

수학적으로 위의 모든 조건은 간단한 방정식으로 만족시킬 수 있다.  
![information theory](https://github.com/jionchu/TIL/blob/master/Neural%20Networks/images/information_theory.png)  
l(x)는 이벤트가 발생할 확률 1/e를 관찰해서 얻어내는 정보의 정량적인 양을 의미한다.  
위 방정식은 쉽고 간단하지만 한 가지 입력값에 대해 한 가지 출력값만을 제공한다. ⇒ 실세계를 모델링하기는 힘들다.
⇒ 이벤트 확률 분포 전체에 존재하는 불확실성을 정량화하면 어떨까?  
⇒ **쉐넌 엔트로피**(Shannon entropy)라고 알려진 측정 방법 사용  
![shannon entropy](https://github.com/jionchu/TIL/blob/master/Neural%20Networks/images/shannon_entropy.png)  

### 2) 엔트로피
이진 신호로 정보를 전달할 때 최소한의 비트 수를 이용해서 효과적으로 커뮤니케이션 하는 방법: 확률적으로 자주 발생하는 이벤트를 알리는 신호는 더 많이 사용될 것이므로 다른 신호보다 더 짧게 만든다.

**엔트로피**: 신호 하나를 표현하는 데 필요한 비트 수  
![entropy](https://github.com/jionchu/TIL/blob/master/Neural%20Networks/images/entropy.png)  
- H(y): 특정한 확률 분포 y를 따르는 이벤트 하나를 표현하기 위한 최적의 비트 수
- yi: 다른 이벤트 i가 발생할 확률

확률밀도가 특정 값에 몰려있으면 엔트로피가 작다고 하고 여러 값에 퍼져 있으면 엔트로피가 크다고 한다.

### 3) 교차 엔트로피
교차 엔트로피를 활용하면 두 개의 확률 분포를 비교할 수 있다.  
뉴럴 네트워크를 사용해 기능 분류와 관련된 처리를 하는 경우 엔트로피 기반의 loss function을 활용한다.  

### 4) 데이터 과학에서 머신러닝으로
뉴런이 화학 물질과 전기적인 임펄스를 커뮤니케이션 매개로 사용하는 것과 같이 인공 뉴런은 수학으로 데이터의 패턴을 표현한다.  

**데이터 과학**(Data Science): 가공되지 않은 데이터에서 활용 가능한 지식을 만들어내는 방법을 다루는 과학 영역. 실세계의 문제를 관찰하고, 다양한 측면이나 특성에서 전체적인 현상을 정량화하고, 원하는 목적을 달성하게 하는 미래의 산출물을 예측하는 과정을 반복하여 지식을 만들어낸다. 머신러닝이란 데이터 과학을 기계에게 가르치는 원리일 뿐.  

우리는 예측에 필요한 정보를 제공하는 연관된 특성들로 실세계의 현상을 표현한 후 미래의 결과를 예측하는 데 이 표현들을 사용한다. 이 표현식을 예측 모델(predictive model)이라고 한다.

#### a. 고차원 공간의 데이터 모델링
TV 화면의 픽셀 색상은 해당 픽셀을 구성하는 RGB 값의 함수로 표현할 수 있다. 데이터 사이언티스트는 이러한 요소를 특징(feature) 혹은 차원(dimension)이라고 부른다. 차원이 라벨링 되어 있다면 우리가 사용하는 모델이 해당 케이스를 학습하는 것을 확인할 수 있으므로 감독하에서 학습 태스크를 다룰 수 있다. 차원이 라벨링 되어 있지 않다면 우리가 가진 데이터 중 비슷한 그룹을 찾는다. 이것을 비지도 머신러닝(unsupervised ML)이라고 부른다. 이러한 방법으로 우리가 가진 정보의 특징을 활용해 실세계의 현상을 표현하는 모델을 만들 수 있다.  

*그렇다면 얼마나 정확한 모델을 만들어야 할까?*  

근본적으로 머신러닝 문제는 n차원 특징 공간으로 정의되는데, 여기에서 n은 우리가 예측하고자 하는 현상이 가진 특징의 수를 의미한다. 서로 다른 특징의 수가 증가함에 따라서 특징을 조합할 수 있는 경우의 수가 기하급수적으로 증가하기 때문에 학습이 어려워지고 더 많은 데이터가 필요해진다. 이러한 문제를 일반적으로 **차원의 저주**(curse of dimensionality)라고 부른다.  

연관된 데이터를 고차원적으로 표현할 수 있다면 예측 함수를 유도할 수 있다. 이 과정에서 고차원의 데이터를 구분하고 분류하는 알고리즘을 사용하여 고차원의 특징 공간을 작은 영역으로 분리하고, 이 영역이 우리가 원하는 결과의 클래스에 대응된다. 즉, 고차원적인 특징 공간에 데이터를 입력한 후 모델이 예측한 출력 클래스와 일치하는지 비교해서 데이터의 출력 클래스를 확실하게 예측할 수 있다.

#### b. 모델과 유스케이스 매칭
하나의 관찰은 여러 특징에 따라 정의되고 각 특징은 다른 특징의 함수로 재정의할 수 있다. 재정의에 따라서 모델에는 새로운 특징들이 추가되고 모델의 복잡도는 높아진다. 따라서 유스케이스에 따라 적절한 특징을 선택함으로써 정의 과정을 어느 지점에서 중단시켜야 한다. **상황을 너무 단순하거나 너무 복잡하게 표현하면 안된다.**  

#### c. 함수적 표현
현상을 완벽하게 모델링 할 수는 없다. 현상의 일부를 기능적인 관점에서 표현할 수 있을 뿐. 데이터는 우리가 이해하고자 하는 현상의 작은 조각인 것이다. 또한 시간의 변화에 따라 특징과 이를 둘러싼 환경은 모두 영향을 받으며 모델의 예측 능력을 감소시킨다.

### 5) 머신러닝의 함정
날씨를 예측하는 문제를 생각해보자.  
몇 가지 특징을 선택한 후 예측 모델을 만든다.
- 기압을 주요 예측 특징으로 선택
- 며칠에 걸쳐 기압을 측정

#### a. 비균형적 클래스 우선도
*며칠 간 맑은 날이 지속된 후 예측 모델이 다음 날도 맑을 것이라고 예측했지만 실제로는 비가 내린다.*  

⇒ 예측해야 할 두 클래스의 충분한 예시를 보지 못했기 때문에 가능성을 정확하게 평가하지 못한 것 (비가 오는 날씨를 접하지 못했기 때문에 항상 맑은 날씨만 예측함)  
⇒ **비균형적 클래스 우선도**(unbalanced class priors)를 가졌다고 한다.

#### b. 과소적합
*두 달 동안 기압 데이터와 각 출력 케이스에 대한 균형 잡힌 관측 데이터를 수집했다. 모델의 예측 정확도는 꾸준히 증가하지만 최적 수준 이하에서 상승을 멈춘다. (ex. 61%) 날씨가 추워지자 모델의 예측 정확도가 급격히 떨어진다.*  

⇒ 모델이 너무 단순해서 변화하는 계절이 만들어내는 데이터의 패턴을 인식하지 못함  
⇒ **과소적합**(underfitting) 문제  
⇒ 모델에 더 많은 데이터를 추가하고 더 나은 특징을 조작하거나, 모델이 가진 수학적 제약사항(정규화를 위한 lambda hyperparameter 등)을 줄임으로써 모델의 정확도와 예측 능력을 향상시킬 수 있음

#### c. 과적합
*수년 동안 데이터를 수집한 끝에 96%의 정확성을 가진 예측 모델을 만들었다. 하지만 다른 지역의 친구에게는 전혀 동작하지 않았다.*

⇒ 모델이 **과적합**(overfitting)되어 버린 것. 모델이 데이터의 사소한 패턴까지 기억하여 적은 정보를 바탕으로 규칙을 생성했기 때문에 샘플 데이터 이외의 데이터를 일반화하지 못함  
⇒ 간단한 모델을 선택하고, 특이값(outlier)이나 오차를 제거해서 데이터의 노이즈를 줄이고, 평균값을 기준으로 모델을 보완할 수 있음  

#### d. 나쁜 데이터
*친구에게 모델에 센서를 붙이는 방법을 설명한 후 데이터셋을 구성해 친구가 사는 지역의 기압과 온도 데이터를 수집한다. 하지만 지붕에 설치된 센서에서 수집된 기압과 온도 데이터는 일관성이 없고 신뢰성이 낮은 형태로 불규칙하게 부풀려진다.*

⇒ 이러한 오차 값이 예측 모델에 유입되면 결과는 덜 최적화될 것이고 부정확한 데이터는 학습된 것을 망가뜨릴 것
⇒ 센서를 교체하거나 센서에서 전달된 오차 값을 무시하는 방법으로 해결

#### e. 관련 없는 특징과 라벨
*드디어 다른 여러 지역에서 얻은 충분한 데이터를 사용해 날씨를 예측하는 데 사용할 수 있을 만큼 명확하고 일반적인 패턴을 찾아냈다. 하지만 모델은 맑고 화창한 날씨가 될 것이라고 예측한 반면 실제로는 토네이도가 들이닥쳤다.*

⇒ 우리는 맑은 날씨와 비가 오는 날씨에 관련된 데이터만 수집했기 때문에 이 모델은 토네이도는 에측하지 못함  
⇒ 어떤 모델에 대해 충분히 만족스러운 예측 정확도를 얻으려면 끊임없이 관련된 특징을 추적해서 각 예측 대상 클래스에 따른 충분한 정보를 수집해야 함  
⇒ 좋은 예측 모델을 가졌다는 것은 현재까지 수집한 데이터를 활용할 수 있는 메커니즘을 발견했고 필연적으로 발생하는 것처럼 보이는 예측의 규칙을 찾아낸 것에 불과함